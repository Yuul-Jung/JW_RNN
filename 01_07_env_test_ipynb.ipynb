{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01-07.env_test.ipynb의 사본",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP4JdNDgkH4mFhBwHahwe4/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yuul-Jung/JW_RNN/blob/master/01_07_env_test_ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pgt0bjokJs_B",
        "colab_type": "text"
      },
      "source": [
        "**<< 참고문헌 및 출처>>**\n",
        "\n",
        "1) 파이썬딥러닝케라스: https://tykimos.github.io/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9TEpGncXiR5",
        "colab_type": "text"
      },
      "source": [
        "#<1> 케라스 기본 개념"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHjxzPe1Xri5",
        "colab_type": "text"
      },
      "source": [
        "케라스에서 제공하는 시퀀스 모델로 원하는 레이어를 쉽게 구성할 수 있다.\n",
        "\n",
        "다중 출력과 같이 좀 더 복잡한 모델을 구성하기 위해서는 케라스 함수 API를 사용하면 된다.\n",
        "\n",
        "케라스 딥러닝 모델 작성 순서는 아래와 같다.\n",
        "\n",
        "1. 데이터셋 생성 \n",
        " - 원본 데이터를 불러오거나 시물레이션 등을 통해 데이터 생성\n",
        " - 데이터로부터 훈련셋, 검증셋, 시험셋을 생성\n",
        " - 딥러닝 모델의 학습 및 평가를 할 수 있도록 포맷 변환\n",
        "\n",
        "2. 모델 구성\n",
        " - 시퀀스 모델을 생성한 뒤 필요한 레이어를 추가하여 구성\n",
        " - 좀 더 복잡한 모델이 필요할 때는 케라스 함수 API를 사용\n",
        "\n",
        "3. 모델 학습과정 설정 : compile() 함수를 사용\n",
        " - 학습하기 전에 학습에 대한 설정을 수행\n",
        " - 손실 함수 및 최적화 방법을 정의\n",
        "\n",
        "4. 모델 학습 : fit() 함수를 사용\n",
        " - 구성한 모델을 훈련셋으로 학습\n",
        "\n",
        "5. 학습과정 모니터링\n",
        " - 모델 학습 시 훈련셋, 검증셋의 손실 및 정확도를 측정\n",
        " - 반복 횟수에 따른 손실 및 정확도 추이를 보면서 학습 상황을 판단\n",
        "\n",
        "6. 모델 평가 : evaluate() 함수를 사용\n",
        " - 준비된 시험셋으로 학습한 모델을 평가\n",
        "\n",
        "7. 모델 사용 : predict() 함수를 사용\n",
        " - 임의의 임력으로 모델에서 출력 도출"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCXQpIxKXSEK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "outputId": "aed5d56f-90bf-4765-cf82-5bc355b84217"
      },
      "source": [
        "#################################################################################\n",
        "# 손글씨 영상 분류하는 모델을 구현\n",
        "# 가로셀 28, 세로셀 28 이미지를 1차원의 784 벡터로 변환 후 학습 및 평가\n",
        "#################################################################################\n",
        "\n",
        "# 0. 사용할 패키지 불러오기\n",
        "from keras.utils import np_utils\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "\n",
        "# 1. 데이터셋 생성하기\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(60000, 784).astype('float32') / 255.0\n",
        "x_test = x_test.reshape(10000, 784).astype('float32') / 255.0\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "\n",
        "# 2. 모델 구성하기\n",
        "model = Sequential()\n",
        "model.add(Dense(units=64, input_dim=28*28, activation='relu'))\n",
        "model.add(Dense(units=10, activation='softmax'))\n",
        "\n",
        "# 3. 모델 학습과정 설정하기\n",
        "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "\n",
        "# 4. 모델 학습시키기\n",
        "hist = model.fit(x_train, y_train, epochs=5, batch_size=32)\n",
        "\n",
        "# 5. 학습과정 살펴보기\n",
        "print('## training loss and acc ##')\n",
        "print(hist.history['loss'])\n",
        "print(hist.history['accuracy'])\n",
        "\n",
        "# 6. 모델 평가하기\n",
        "loss_and_metrics = model.evaluate(x_test, y_test, batch_size=32)\n",
        "print('## evaluation loss and_metrics ##')\n",
        "print(loss_and_metrics)\n",
        "\n",
        "# 7. 모델 사용하기\n",
        "xhat = x_test[0:1]\n",
        "yhat = model.predict(xhat)\n",
        "print('## yhat ##')\n",
        "print(yhat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 2s 0us/step\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.6927 - accuracy: 0.8234\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 0.3474 - accuracy: 0.9027\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 0.2980 - accuracy: 0.9162\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 0.2693 - accuracy: 0.9241\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 0.2481 - accuracy: 0.9305\n",
            "## training loss and acc ##\n",
            "[0.6926682615756988, 0.3474385932882627, 0.2980140088995298, 0.2692863485296567, 0.24813596321642398]\n",
            "[0.82336664, 0.9027333, 0.91625, 0.9241, 0.93053335]\n",
            "10000/10000 [==============================] - 0s 22us/step\n",
            "## evaluation loss and_metrics ##\n",
            "[0.23152339048683643, 0.9340000152587891]\n",
            "## yhat ##\n",
            "[[3.4158089e-04 7.9409361e-08 2.7128935e-04 1.4280526e-03 3.2774460e-06\n",
            "  4.8226982e-05 1.5319029e-07 9.9685824e-01 5.8444097e-05 9.9067471e-04]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i733lvKxUxMj",
        "colab_type": "text"
      },
      "source": [
        "#딥러닝 기본모델 구동 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "la3njtG-S2wI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "108fbb5a-3360-42c7-cbb7-0f6e9691a204"
      },
      "source": [
        "# 0. 사용할 패키지 불러오기\n",
        "from keras.utils import np_utils\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "\n",
        "# 1. 데이터셋 생성하기\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
        "X_train = X_train.reshape(60000, 784).astype('float32') / 255.0\n",
        "X_test = X_test.reshape(10000, 784).astype('float32') / 255.0\n",
        "Y_train = np_utils.to_categorical(Y_train)\n",
        "Y_test = np_utils.to_categorical(Y_test)\n",
        "\n",
        "# 2. 모델 구성하기\n",
        "model = Sequential()\n",
        "model.add(Dense(units=64, input_dim=28*28, activation='relu'))\n",
        "model.add(Dense(units=10, activation='softmax'))\n",
        "\n",
        "# 3. 모델 학습과정 설정하기\n",
        "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "\n",
        "# 4. 모델 학습시키기\n",
        "model.fit(X_train, Y_train, epochs=5, batch_size=32)\n",
        "\n",
        "# 6. 모델 평가하기\n",
        "loss_and_metrics = model.evaluate(X_test, Y_test, batch_size=32)\n",
        "\n",
        "print('loss_and_metrics : ' + str(loss_and_metrics))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 2s 0us/step\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.6749 - accuracy: 0.8244\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.3459 - accuracy: 0.9036\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 3s 44us/step - loss: 0.2968 - accuracy: 0.9156\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 2s 40us/step - loss: 0.2675 - accuracy: 0.9245\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 0.2459 - accuracy: 0.9305\n",
            "10000/10000 [==============================] - 0s 21us/step\n",
            "loss_and_metrics : [0.23371364426612853, 0.9348999857902527]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9v9IU7zVAeV",
        "colab_type": "text"
      },
      "source": [
        "# 딥러닝 모델 가시화 기능 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EAQZkS9Tx8R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "outputId": "c41219e4-d918-434d-f3da-4e5193592951"
      },
      "source": [
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"295pt\" viewBox=\"0.00 0.00 326.00 221.00\" width=\"435pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1.3333 1.3333) rotate(0) translate(4 217)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-217 322,-217 322,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140374809573752 -->\n<g class=\"node\" id=\"node1\">\n<title>140374809573752</title>\n<polygon fill=\"none\" points=\"0,-166.5 0,-212.5 318,-212.5 318,-166.5 0,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-185.8\">dense_1_input: InputLayer</text>\n<polyline fill=\"none\" points=\"173,-166.5 173,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"202\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"173,-189.5 231,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"202\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"231,-166.5 231,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"274.5\" y=\"-197.3\">(None, 784)</text>\n<polyline fill=\"none\" points=\"231,-189.5 318,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"274.5\" y=\"-174.3\">(None, 784)</text>\n</g>\n<!-- 140376458628568 -->\n<g class=\"node\" id=\"node2\">\n<title>140376458628568</title>\n<polygon fill=\"none\" points=\"33,-83.5 33,-129.5 285,-129.5 285,-83.5 33,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-102.8\">dense_1: Dense</text>\n<polyline fill=\"none\" points=\"140,-83.5 140,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"169\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"140,-106.5 198,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"169\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"198,-83.5 198,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"241.5\" y=\"-114.3\">(None, 784)</text>\n<polyline fill=\"none\" points=\"198,-106.5 285,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"241.5\" y=\"-91.3\">(None, 64)</text>\n</g>\n<!-- 140374809573752&#45;&gt;140376458628568 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140374809573752-&gt;140376458628568</title>\n<path d=\"M159,-166.3799C159,-158.1745 159,-148.7679 159,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"162.5001,-139.784 159,-129.784 155.5001,-139.784 162.5001,-139.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140374809572856 -->\n<g class=\"node\" id=\"node3\">\n<title>140374809572856</title>\n<polygon fill=\"none\" points=\"36.5,-.5 36.5,-46.5 281.5,-46.5 281.5,-.5 36.5,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"90\" y=\"-19.8\">dense_2: Dense</text>\n<polyline fill=\"none\" points=\"143.5,-.5 143.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"172.5\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"143.5,-23.5 201.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"172.5\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"201.5,-.5 201.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"241.5\" y=\"-31.3\">(None, 64)</text>\n<polyline fill=\"none\" points=\"201.5,-23.5 281.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"241.5\" y=\"-8.3\">(None, 10)</text>\n</g>\n<!-- 140376458628568&#45;&gt;140374809572856 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140376458628568-&gt;140374809572856</title>\n<path d=\"M159,-83.3799C159,-75.1745 159,-65.7679 159,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"162.5001,-56.784 159,-46.784 155.5001,-56.784 162.5001,-56.784\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-leH2YC2gop",
        "colab_type": "text"
      },
      "source": [
        "# 딥러닝 모델 저장 기능 확인"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFcnZY6yUCAZ",
        "colab_type": "text"
      },
      "source": [
        "케라스 딥러닝 모델 저장 기능 확인, 로컬 디렉토리에 'mnist_mlp_model.h5'파일이 생성되면 정상적으로 작동"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbMg-Sv_UJah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model.save('mnist_mlp_model.h5')\n",
        "model = load_model('mnist_mlp_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItAWYQVAUuDk",
        "colab_type": "text"
      },
      "source": [
        "# 딥러닝 엔진 바꾸기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROIQn7VnUAiP",
        "colab_type": "text"
      },
      "source": [
        "\"beckend\": \"tensorflow\"\n",
        "\n",
        "\"beckend\": \"theano\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilmzQwol1T5P",
        "colab_type": "text"
      },
      "source": [
        "<< 참고문헌 및 출처>>\n",
        "\n",
        "1) 파이썬딥러닝케라스: https://tykimos.github.io/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dw-SIxS1Ihrk",
        "colab_type": "text"
      },
      "source": [
        "#<2> 딥러닝 개념 파악"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Owe6hY8nIepP",
        "colab_type": "text"
      },
      "source": [
        "딥러닝 모델을 학습시키려면 데이터셋이 필요하다.\n",
        "\n",
        "해결하고자 하는 문제 및 만들고자 하는 모델에 따라 데이터셋 설계도 달라진다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T80qKsvkd-A6",
        "colab_type": "text"
      },
      "source": [
        "#1.. 데이터 정의 : 훈련셋, 검증셋, 시험셋"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnfMfQEVNbYO",
        "colab_type": "text"
      },
      "source": [
        "1-0. 훈련셋, 검증셋, 시험셋\n",
        "\n",
        "- <가정> 수능 볼 학생 3명이 있다. 이 세명 중 수능을 가장 잘 볼지 알아맞혀라. (단, 모의고사 5회분과 작년 수능문제 1회분을 가지고 있다.)\n",
        " - 모의고사 5회분 : 훈련셋\n",
        " - 작년 수능 문제 : 시험셋\n",
        " - 학생 3명 : 모델 3개\n",
        " - 올해 수능 문제 : 실제 데이터(아직 보지 못한 데이터, Unseen data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JfWFK4geOo7",
        "colab_type": "text"
      },
      "source": [
        "# 경우 1 (불가능)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wu1pdt7-dokb",
        "colab_type": "text"
      },
      "source": [
        "1-1. 경우 1 (불가능)\n",
        "- <설정> \n",
        " - 훈련셋 : 모의고사 1~5회분, 작년수능문제\n",
        " - 시험셋 : 올해 수능 문제\n",
        "- <결론> 올해 수능 문제를 수능 전에 알아낼 수 없으므로 (불가능)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxSuM6h1eNlM",
        "colab_type": "text"
      },
      "source": [
        "# 경우 2 (훈련셋과 시험셋만 있음)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSOwNB58djIZ",
        "colab_type": "text"
      },
      "source": [
        "1-2. 경우 2 (훈련셋과 시험셋만 있음)\n",
        "- <설정> \n",
        " - 훈련셋 : 모의고사 1~5회분\n",
        " - 시험셋 : 작년 수능 문제(공정한 평가를 위해 작년 수능 문제를 훈련셋에 포함 시키면 안됨)\n",
        "- <결론> 작년 수능 문제로 점수가 높다고 해서 올해 수능도 점수가 높을 지 장담은 못하지만 그나마 해볼 수 있는 평가 방법"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LToAtBWzeXDf",
        "colab_type": "text"
      },
      "source": [
        "# 경우 3 (훈련셋, 검증셋, 시험셋이 있음)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJG0qBkRdVs-",
        "colab_type": "text"
      },
      "source": [
        "1-3. 경우 3 (훈련셋, 검증셋, 시험셋이 있음)\n",
        "- <이유> 학생들이 스스로 학습상태를 확인하고 학습방법을 바꾸거나 학습을 중단하는 시점을 정하도록 검증셋을 활용\n",
        "- <설정>\n",
        " - 훈련셋 : 모의고사 1~4회분\n",
        " - 검증셋 : 모의고사 5회분\n",
        " - 시험셋 : 작년 수능 문제\n",
        "- <효과> \n",
        " - (1) 학습 방법을 바꾼 후 훈련셋으로 학습을 해보고 검증셋으로 평가해 볼 수 있다. 검증셋으로 가장 높은 평가를 받은 학습 방법이 최적의 학습 방법이라고 생각할 수 있다. 이러한 학습 방법을 결정하는 파라미터를 하이퍼파라미터(hyperparameter)라고하고 최적의 학습 방법을 찾기 위해 하이퍼파라미터를 조정(하이퍼파라미터 튜닝)이라 한다. 검증셋이 있다면 스스로 평가하면서 적절한 학습 방법을 찾아볼 수 있다.\n",
        " - (2) 얼마 정도 반복 학습이 좋을 지를 정하기 위해서 검증셋을 사용할 수 있다. 훈련셋을 몇 번 반복해서 학습할 것인가를 정하는 것이 에포크(epochs)이며, 초기에는 에포크가 증가될수록 검증셋의 평가 결과도 좋아진다. 에포크를 계속 증가시키다보면 더 이상 검증셋의 평가는 높아지지 않고 오버피팅이 되어 오히려 틀린 개수가 많아진다. 이 시점이 적정 반복횟수로 보고 학습을 중단한다. 이를 조기 종료(early stopping)라고 한다. 검증셋이 있다면 학습 중단 시점을 정할 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3Eizs-4eeR4",
        "colab_type": "text"
      },
      "source": [
        "# 경우 4 (훈련셋을 돌려가며 교차검증)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J22FFphrdTcg",
        "colab_type": "text"
      },
      "source": [
        "**1-4. 경우 4 (훈련셋을 돌려가며 교차검증)**\n",
        "- <이유> 모의고사 5회로만 검증셋을 사용할 경우 객관적인 평가가 이루어졌다고 보기 어렵다. 이때 사용하는 것이 교차검증(cross-validation)이다.\n",
        " - 모의고사 5회에서 출제가 되지 않는 분야가 있거나 \n",
        " - 작년수능이나 홀해 수능문제와 많이 다를 수도 있고\n",
        " - 난이도 및 범위가 다를 수 있기때문이다. \n",
        "- <설정> \n",
        " - 모의고사 1~4회를 학습한 뒤 모의고사 5회로 검증, \n",
        " - 학습된 상태를 초기화한 후 다시 모의고사 1~3회, 5회로 학습한 뒤 모의고사 4회로 검증\n",
        " - 학습된 상태를 초기화한 후 다시 모의고사 1~2회와 4,5회로 학습한 뒤 모의고사 3회로 검증\n",
        " - 계속해서 모의고사 1회까지 검증한다.\n",
        "- <결론> \n",
        " - 다섯번의 검증 결과에 대한 평균을 내어 이 평균값, 분산으로 성능을 정의\n",
        " - 검증셋이 다르다고 해서 결과가 차이나는 것보다 평균이 낮더라도 안정적인 결과를 내는 것이 더 좋은 모델일 수 있음\n",
        "- <문제점>\n",
        " - 교차검증은 계산량이 많기 때문에 데이터 수가 많지 않을 때 사용하며, 딥러닝 모델에서는 대량의 데이터를 사용하므로 잘 사용하지 않는다고 함 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mISRQVN22oKk",
        "colab_type": "text"
      },
      "source": [
        "#2.. 모델 구성\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmZ8JJfh3JOO",
        "colab_type": "text"
      },
      "source": [
        "- 레이어를 통해 신경망 모델을 구성\n",
        " - 다층 퍼셉트론 신경망 모델\n",
        " - 컨볼루션 신경망 모델\n",
        " - 순환 신경망 모델"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bA7Q6C8Sh_gh",
        "colab_type": "text"
      },
      "source": [
        "#3.. 학습과정이란"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sE0AIWE9ifRs",
        "colab_type": "text"
      },
      "source": [
        "# 3.. 학습과정 사용"
      ]
    }
  ]
}